{
  "ollamaModels": [
    {
      "id": "llama3",
      "name": "Llama 3 (8B)",
      "description": "Meta's advanced open-source LLM",
      "parameters": {
        "temperature": 0.7,
        "top_p": 0.9,
        "max_tokens": 2048
      },
      "installed": false
    },
    {
      "id": "mistral",
      "name": "Mistral (7B)",
      "description": "Powerful open-source language model",
      "parameters": {
        "temperature": 0.7,
        "top_p": 0.9,
        "max_tokens": 2048
      },
      "installed": false
    },
    {
      "id": "codellama",
      "name": "CodeLlama (7B)",
      "description": "Specialized for code generation and understanding",
      "parameters": {
        "temperature": 0.7,
        "top_p": 0.95,
        "max_tokens": 4096
      },
      "installed": false
    },
    {
      "id": "vicuna",
      "name": "Vicuna (7B)",
      "description": "Conversational assistant based on LLaMA",
      "parameters": {
        "temperature": 0.7,
        "top_p": 0.9,
        "max_tokens": 2048
      },
      "installed": false
    },
    {
      "id": "qwen:0.5b",
      "name": "Qwen 2.5 (0.5B)",
      "description": "Efficient small language model from Alibaba",
      "parameters": {
        "temperature": 2,
        "top_p": 1,
        "max_tokens": 8192
      },
      "installed": true
    }
  ],
  "defaultSettings": {
    "apiEndpoint": "http://localhost:11434",
    "defaultModel": "qwen:0.5b",
    "chatSettings": {
      "streamResponses": true,
      "saveHistory": true,
      "maxHistoryItems": 100,
      "defaultModel": "qwen:0.5b"
    }
  }
}